# Social Worker BERT Configuration Example
# This configuration demonstrates both single file and separate files modes

# Data Configuration
data:
  # Option 1: Single file mode (legacy)
  # data_file: './tri.csv'
  # mode: 'single_file'
  # test_size: 0.1
  # val_size: 0.1
  
  # Option 2: Separate files mode (new)
  train_file: './data/train.csv'
  test_file: './data/test.csv'
  val_file: './data/validation.csv'  # Optional: if not provided, validation will be split from training data
  mode: 'separate_files'
  val_size: 0.1  # Only used if val_file is not provided
  
  # Option 2b: Separate files mode without validation file
  # train_file: './data/train.csv'
  # test_file: './data/test.csv'
  # mode: 'separate_files'
  # val_size: 0.1  # Validation split from training data
  
  # Common data processing parameters
  annotator_columns: ['Anthea', 'Karen', 'Kimmy']
  message_column: 'message'
  random_state: 42
  label_strategy: 'ensemble'  # 'ensemble', 'majority', 'individual'
  min_annotator_agreement: 2

# Model Configuration
model:
  model_name: 'bert-large-uncased'
  max_length: 512
  dropout_prob: 0.1

# Training Configuration
training:
  batch_size: 32
  learning_rate: 8.0e-05
  num_epochs: 10
  warmup_steps: 50
  weight_decay: 0.01
  use_gpu: true
  save_model: true
  model_save_path: 'social_worker_bert_model'
  gradient_clip_norm: 1.0

# Class Imbalance Handling
class_imbalance:
  use_class_weights: true
  weight_method: 'balanced'
  min_samples_threshold: 5
  rare_label_handling: 'remove'
  focal_loss: true
  focal_alpha: 0.25
  focal_gamma: 2.0

# Data Augmentation
data_augmentation:
  enable: true
  rare_threshold: 1.0
  augment_factor: 3
  methods: ['paraphrase', 'synonym_replacement']

# Evaluation Configuration
evaluation:
  classification_threshold: 0.5
  metrics: ['f1_macro', 'f1_micro', 'precision', 'recall']
  save_detailed_predictions: true
